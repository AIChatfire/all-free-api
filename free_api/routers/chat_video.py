#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Project      : AI.  @by PyCharm
# @File         : chat_video
# @Time         : 2024/7/25 10:59
# @Author       : betterme
# @WeChat       : meutils
# @Software     : PyCharm
# @Description  :

from meutils.pipe import *
from meutils.schemas.runwayml_types import RunwayRequest, Options
from meutils.schemas.openai_types import ChatCompletionRequest
from meutils.schemas.task_types import Task

from meutils.llm.openai_utils import create_chat_completion, create_chat_completion_chunk, chat_completion

from meutils.serving.fastapi.dependencies.auth import get_bearer_token, HTTPAuthorizationCredentials
from fastapi import APIRouter, File, UploadFile, Query, Form, Depends, Request, HTTPException, status, BackgroundTasks, \
    Body
from sse_starlette import EventSourceResponse
from openai.types.chat import ChatCompletion, ChatCompletionChunk
from openai import AsyncOpenAI

router = APIRouter()
TAGS = ["VIDEO"]

ChatCompletionResponse = Union[ChatCompletion, List[ChatCompletionChunk]]


@router.post("/chat/completions")
async def create_chat_completions(
        request: ChatCompletionRequest,
        auth: Optional[HTTPAuthorizationCredentials] = Depends(get_bearer_token),
        vip: Optional[bool] = Query(False),
        backgroundtasks: BackgroundTasks = BackgroundTasks,
):
    api_key = auth and auth.credentials or None
    logger.debug(request.model_dump_json(indent=4))

    if request.last_content.startswith(  # è·³è¿‡nextchat
            ("ä½¿ç”¨å››åˆ°äº”ä¸ªå­—ç›´æ¥è¿”å›è¿™å¥è¯çš„ç®€è¦ä¸»é¢˜",
             "ç®€è¦æ€»ç»“ä¸€ä¸‹å¯¹è¯å†…å®¹ï¼Œç”¨ä½œåç»­çš„ä¸Šä¸‹æ–‡æç¤º promptï¼Œæ§åˆ¶åœ¨ 200 å­—ä»¥å†…")):
        return

        # todo: å…¶ä»–æ¨¡å‹ï¼Œç›®å‰ gen3

    video_request = RunwayRequest(options=Options(text_prompt=request.last_content, exploreMode=not vip))

    async def create_video(task_type="runwayml"):
        headers = {'Authorization': f'Bearer {api_key}'}
        payload = video_request.model_dump(exclude_none=True)

        async with httpx.AsyncClient(base_url="https://api.chatfire.cn/tasks", headers=headers, timeout=100) as client:
            response = await client.post(f"/{task_type}", json=payload)
            if response.is_success:
                return Task(**response.json())

    future_task = asyncio.create_task(create_video())  # å¼‚æ­¥æ‰§è¡Œ
    if request.stream:
        async def gen_chunks():
            for i in f"> â–¶ï¸ æ­£åœ¨åˆ¶ä½œä¸­\n\n```json\n{video_request.model_dump_json(indent=4, exclude_none=True)}\n```\n\n":
                await asyncio.sleep(0.03)
                yield i

            task = await future_task
            task_url = f"https://api.chatfire.cn/tasks/{task.id}"
            logger.debug(task_url)
            yield f"> ğŸ¤« ä»»åŠ¡åˆ›å»ºæˆåŠŸï¼Œ[ä»»åŠ¡è¯¦æƒ…]({task_url})\n\n"

            yield f" ğŸ¤« [ä»»åŠ¡è¿›åº¦]("
            for i in range(100):
                await asyncio.sleep(3)

                data = (await httpx.AsyncClient().get(task_url)).json().get("task")
                if data.get("status") != "SUCCEEDED":
                    # progressText = data.get("progressText")
                    progressRatio = float(data.get("progressRatio") or 0)
                    if progressRatio:
                        yield f"{progressRatio:.2%}"
                else:
                    yield ")ğŸ‰ğŸ‰ğŸ‰\n\n"  # éšè—è¿›åº¦æ¡
                    video_url = data.get("artifacts")[0].get("url")
                    yield f"[ä¸‹è½½åœ°å€]({video_url})\n\n"
                    yield f"![è§†é¢‘åœ°å€]({video_url})\n\n"
                    break

        chunks = create_chat_completion_chunk(gen_chunks())
        return EventSourceResponse(chunks)
    else:
        return create_chat_completion(chat_completion)


if __name__ == '__main__':
    from meutils.serving.fastapi import App

    app = App()

    app.include_router(router, '/v1')

    app.run()
    # for i in range(10):
    #     send_message(f"å…œåº•æ¨¡å‹", title="github_copilot")
